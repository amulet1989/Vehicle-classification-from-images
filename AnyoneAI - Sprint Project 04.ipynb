{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oGwrUZSxXSuG"
   },
   "source": [
    "# AnyoneAI - Sprint Project 04\n",
    "> Vehicle Classification\n",
    "\n",
    "You've been learning a lot about Deep Learning Algorithms, now we you're gonna be asked to put it all together. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1680033779007,
     "user": {
      "displayName": "Pablo Pastore",
      "userId": "13868799798828179067"
     },
     "user_tz": 180
    },
    "id": "5bcJoaR6YahS",
    "outputId": "8ffde720-b93c-4b78-e804-f820bf2dbd7e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "IN_COLAB = \"google.colab\" in sys.modules\n",
    "IN_COLAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26895,
     "status": "ok",
     "timestamp": 1680028888362,
     "user": {
      "displayName": "Pablo Pastore",
      "userId": "13868799798828179067"
     },
     "user_tz": 180
    },
    "id": "_9ohQ9PnXeZx",
    "outputId": "640e4dd1-946d-491e-a010-113537e668f7"
   },
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "\n",
    "    drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 226,
     "status": "ok",
     "timestamp": 1680033781336,
     "user": {
      "displayName": "Pablo Pastore",
      "userId": "13868799798828179067"
     },
     "user_tz": 180
    },
    "id": "MOmDt--lXwUQ",
    "outputId": "107fe30a-da87-4927-b51f-a6532397dce6"
   },
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    # Put here the full path to the folder having your Sprint project code\n",
    "    # e.g. \"/content/drive/MyDrive/assignment\"\n",
    "    ROOT_DIR = \"/content/drive/MyDrive/assignment\"\n",
    "    %cd $ROOT_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z3twXxeDrr8u"
   },
   "source": [
    "## Install dependencies (Only for Colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 89953,
     "status": "ok",
     "timestamp": 1680028980620,
     "user": {
      "displayName": "Pablo Pastore",
      "userId": "13868799798828179067"
     },
     "user_tz": 180
    },
    "id": "nxv7tDMorr8y",
    "outputId": "a41ca9a0-8596-4f83-cff1-58ff94a28860"
   },
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    # This will make sure you have installed all the proper dependencies\n",
    "    # Instal dependencies\n",
    "    !pip install -r requirements.txt\n",
    "    # We can access to GPUs in Colab, so install GPU version of tensorflow\n",
    "    !pip install tensorflow-gpu==2.8.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B_k9xfyOXSuH"
   },
   "source": [
    "## 1. Introduction\n",
    "\n",
    "This is a Multi-class Classification task: we want to predict, given a picture of a vehicle, which of the possible 25 classes is the correct vehicle make-model.\n",
    "\n",
    "The dataset is composed of JPG images, already stored in folders containing the label (vehicle make-model), separated in train and test sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 6562,
     "status": "ok",
     "timestamp": 1680033789818,
     "user": {
      "displayName": "Pablo Pastore",
      "userId": "13868799798828179067"
     },
     "user_tz": 180
    },
    "id": "nhrF6OAAXSuI"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from src import data_utils, models, config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vqPF-5jcXSuI"
   },
   "source": [
    "### Getting the data\n",
    "\n",
    "To access the data for this project, you only need to execute the code below. This will download a zip file `cars_25_dataset.zip` containing inside:\n",
    "\n",
    "- `car_ims_dataset`: Folder whit train and test images, already classified in sub-folders with the corresponding vehicle label.\n",
    "\n",
    "- `train_dataset_annos.csv` and `test_dataset_annos.csv`: Train and test images annotations provided in CSV file format. You will not need these files unless you want to solve the optional exercises.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SlO06ncGXSuJ"
   },
   "source": [
    "1.1. Download the training and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 2957,
     "status": "ok",
     "timestamp": 1680033792773,
     "user": {
      "displayName": "Pablo Pastore",
      "userId": "13868799798828179067"
     },
     "user_tz": 180
    },
    "id": "DihttAYcXSuJ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1ueaI8NJLS73Eq8Kx9ctdy5hK3vD53_Jb&confirm=t\n",
      "To: d:\\Alexander\\Cursos Programación\\AnyoneAI ML\\Sprint 4\\assignment\\assignment\\dataset\\cars_25_dataset.zip\n",
      "100%|██████████| 116M/116M [00:05<00:00, 21.7MB/s] \n"
     ]
    }
   ],
   "source": [
    "if IN_COLAB:\n",
    "    config.DATASET_ROOT_PATH = \"/content/dataset/\"\n",
    "\n",
    "data_utils.download_datasets(config.DATASET_ROOT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3nu9NVUbXSuJ"
   },
   "source": [
    "1.2. Setup some variables you will use during training the model.\n",
    "\n",
    "The default values used here should work fine for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1680033792773,
     "user": {
      "displayName": "Pablo Pastore",
      "userId": "13868799798828179067"
     },
     "user_tz": 180
    },
    "id": "X8Dc0jEwXSuJ"
   },
   "outputs": [],
   "source": [
    "# Dataset folder\n",
    "DATASET_FOLDER = os.path.join(config.DATASET_ROOT_PATH, config.DATASET_FILENAME)\n",
    "DATASET_FOLDER = os.path.join(config.DATASET_ROOT_PATH, \"eu-car-dataset_subset\")\n",
    "\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nTiXjhZxXSuK"
   },
   "source": [
    "1.3. Load the training and testing images as a Tensorflow dataset (`tf.data.Dataset`).\n",
    "\n",
    "Note that it's not a good idea to load all the images into memory because they may need more RAM than the one installed in the system. This is why we create generators using the `image_dataset_from_directory()` function, which loads the images only when they are needed and then releases the memory for loading another batch of new images from the disk.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gM2-j_l3XSuK"
   },
   "source": [
    "**Don't change anything in this cell, just make it run correctly**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1367,
     "status": "ok",
     "timestamp": 1680033794137,
     "user": {
      "displayName": "Pablo Pastore",
      "userId": "13868799798828179067"
     },
     "user_tz": 180
    },
    "id": "D79NvbS3XSuK",
    "outputId": "90b3dee1-ed93-45c2-c0a0-a56a118dd1f1"
   },
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xf3 in position 34: invalid continuation byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Load train and test datasets\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m train_ds \u001b[39m=\u001b[39m keras\u001b[39m.\u001b[39;49mpreprocessing\u001b[39m.\u001b[39;49mimage_dataset_from_directory(\n\u001b[0;32m      3\u001b[0m     directory\u001b[39m=\u001b[39;49mos\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(DATASET_FOLDER, \u001b[39m\"\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m      4\u001b[0m     labels\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39minferred\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m      5\u001b[0m     label_mode\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcategorical\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m      6\u001b[0m     seed\u001b[39m=\u001b[39;49m\u001b[39m123\u001b[39;49m,\n\u001b[0;32m      7\u001b[0m     image_size\u001b[39m=\u001b[39;49m(img_height, img_width),\n\u001b[0;32m      8\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[0;32m      9\u001b[0m )\n\u001b[0;32m     11\u001b[0m test_ds \u001b[39m=\u001b[39m keras\u001b[39m.\u001b[39mpreprocessing\u001b[39m.\u001b[39mimage_dataset_from_directory(\n\u001b[0;32m     12\u001b[0m     directory\u001b[39m=\u001b[39mos\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(DATASET_FOLDER, \u001b[39m\"\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m     13\u001b[0m     labels\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39minferred\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     17\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m     18\u001b[0m )\n",
      "File \u001b[1;32md:\\Alexander\\Cursos Programación\\AnyoneAI ML\\Sprint 4\\assignment\\assignment\\Spr4_venv\\Lib\\site-packages\\keras\\utils\\image_dataset.py:210\u001b[0m, in \u001b[0;36mimage_dataset_from_directory\u001b[1;34m(directory, labels, label_mode, class_names, color_mode, batch_size, image_size, shuffle, seed, validation_split, subset, interpolation, follow_links, crop_to_aspect_ratio, **kwargs)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[39mif\u001b[39;00m seed \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    209\u001b[0m     seed \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mrandint(\u001b[39m1e6\u001b[39m)\n\u001b[1;32m--> 210\u001b[0m image_paths, labels, class_names \u001b[39m=\u001b[39m dataset_utils\u001b[39m.\u001b[39;49mindex_directory(\n\u001b[0;32m    211\u001b[0m     directory,\n\u001b[0;32m    212\u001b[0m     labels,\n\u001b[0;32m    213\u001b[0m     formats\u001b[39m=\u001b[39;49mALLOWLIST_FORMATS,\n\u001b[0;32m    214\u001b[0m     class_names\u001b[39m=\u001b[39;49mclass_names,\n\u001b[0;32m    215\u001b[0m     shuffle\u001b[39m=\u001b[39;49mshuffle,\n\u001b[0;32m    216\u001b[0m     seed\u001b[39m=\u001b[39;49mseed,\n\u001b[0;32m    217\u001b[0m     follow_links\u001b[39m=\u001b[39;49mfollow_links,\n\u001b[0;32m    218\u001b[0m )\n\u001b[0;32m    220\u001b[0m \u001b[39mif\u001b[39;00m label_mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(class_names) \u001b[39m!=\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[0;32m    221\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    222\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mWhen passing `label_mode=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m`, there must be exactly 2 \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    223\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mclass_names. Received: class_names=\u001b[39m\u001b[39m{\u001b[39;00mclass_names\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    224\u001b[0m     )\n",
      "File \u001b[1;32md:\\Alexander\\Cursos Programación\\AnyoneAI ML\\Sprint 4\\assignment\\assignment\\Spr4_venv\\Lib\\site-packages\\keras\\utils\\dataset_utils.py:542\u001b[0m, in \u001b[0;36mindex_directory\u001b[1;34m(directory, labels, formats, class_names, shuffle, seed, follow_links)\u001b[0m\n\u001b[0;32m    540\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    541\u001b[0m     subdirs \u001b[39m=\u001b[39m []\n\u001b[1;32m--> 542\u001b[0m     \u001b[39mfor\u001b[39;00m subdir \u001b[39min\u001b[39;00m \u001b[39msorted\u001b[39m(tf\u001b[39m.\u001b[39;49mio\u001b[39m.\u001b[39;49mgfile\u001b[39m.\u001b[39;49mlistdir(directory)):\n\u001b[0;32m    543\u001b[0m         \u001b[39mif\u001b[39;00m tf\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mgfile\u001b[39m.\u001b[39misdir(tf\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mgfile\u001b[39m.\u001b[39mjoin(directory, subdir)):\n\u001b[0;32m    544\u001b[0m             \u001b[39mif\u001b[39;00m subdir\u001b[39m.\u001b[39mendswith(\u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[1;32md:\\Alexander\\Cursos Programación\\AnyoneAI ML\\Sprint 4\\assignment\\assignment\\Spr4_venv\\Lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py:767\u001b[0m, in \u001b[0;36mlist_directory_v2\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    751\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mio.gfile.listdir\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    752\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlist_directory_v2\u001b[39m(path):\n\u001b[0;32m    753\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Returns a list of entries contained within a directory.\u001b[39;00m\n\u001b[0;32m    754\u001b[0m \n\u001b[0;32m    755\u001b[0m \u001b[39m  The list is in arbitrary order. It does not contain the special entries \".\"\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    765\u001b[0m \u001b[39m    errors.NotFoundError if directory doesn't exist\u001b[39;00m\n\u001b[0;32m    766\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 767\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_directory(path):\n\u001b[0;32m    768\u001b[0m     \u001b[39mraise\u001b[39;00m errors\u001b[39m.\u001b[39mNotFoundError(\n\u001b[0;32m    769\u001b[0m         node_def\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    770\u001b[0m         op\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    771\u001b[0m         message\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCould not find directory \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(path))\n\u001b[0;32m    773\u001b[0m   \u001b[39m# Convert each element to string, since the return values of the\u001b[39;00m\n\u001b[0;32m    774\u001b[0m   \u001b[39m# vector of string should be interpreted as strings, not bytes.\u001b[39;00m\n",
      "File \u001b[1;32md:\\Alexander\\Cursos Programación\\AnyoneAI ML\\Sprint 4\\assignment\\assignment\\Spr4_venv\\Lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py:689\u001b[0m, in \u001b[0;36mis_directory\u001b[1;34m(dirname)\u001b[0m\n\u001b[0;32m    679\u001b[0m \u001b[39m@tf_export\u001b[39m(v1\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mgfile.IsDirectory\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m    680\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mis_directory\u001b[39m(dirname):\n\u001b[0;32m    681\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Returns whether the path is a directory or not.\u001b[39;00m\n\u001b[0;32m    682\u001b[0m \n\u001b[0;32m    683\u001b[0m \u001b[39m  Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[39m    True, if the path is a directory; False otherwise\u001b[39;00m\n\u001b[0;32m    688\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 689\u001b[0m   \u001b[39mreturn\u001b[39;00m is_directory_v2(dirname)\n",
      "File \u001b[1;32md:\\Alexander\\Cursos Programación\\AnyoneAI ML\\Sprint 4\\assignment\\assignment\\Spr4_venv\\Lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py:703\u001b[0m, in \u001b[0;36mis_directory_v2\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    694\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Returns whether the path is a directory or not.\u001b[39;00m\n\u001b[0;32m    695\u001b[0m \n\u001b[0;32m    696\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    700\u001b[0m \u001b[39m  True, if the path is a directory; False otherwise\u001b[39;00m\n\u001b[0;32m    701\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    702\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 703\u001b[0m   \u001b[39mreturn\u001b[39;00m _pywrap_file_io\u001b[39m.\u001b[39;49mIsDirectory(compat\u001b[39m.\u001b[39;49mpath_to_bytes(path))\n\u001b[0;32m    704\u001b[0m \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mOpError:\n\u001b[0;32m    705\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xf3 in position 34: invalid continuation byte"
     ]
    }
   ],
   "source": [
    "# Load train and test datasets\n",
    "train_ds = keras.preprocessing.image_dataset_from_directory(\n",
    "    directory=os.path.join(DATASET_FOLDER, \"train\"),\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "test_ds = keras.preprocessing.image_dataset_from_directory(\n",
    "    directory=os.path.join(DATASET_FOLDER, \"test\"),\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DBzwpVV2XSuK"
   },
   "source": [
    "**Checkpoint:** The cell above should output the following message:\n",
    "\n",
    "```code\n",
    "Found 7509 files belonging to 25 classes.\n",
    "Found 1875 files belonging to 25 classes.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X5ag5bjyXSuL"
   },
   "source": [
    "## 2. Basic EDA\n",
    "\n",
    "Let's load and display some pictures with their labels.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CiSi6U8CXSuL"
   },
   "source": [
    "2.1. Take the class names automatically inferred from the data generator and assign to `class_names` variable. We will use this to do some EDA and also to define the output units in the classification layer of our model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yIGNf-xhXSuL"
   },
   "source": [
    "**Don't change anything in this cell, just make it run correctly**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1680033794137,
     "user": {
      "displayName": "Pablo Pastore",
      "userId": "13868799798828179067"
     },
     "user_tz": 180
    },
    "id": "xEvAmzyaXSuL",
    "outputId": "21f4372d-ae52-4ae7-f97f-8d98a5afa771"
   },
   "outputs": [],
   "source": [
    "class_names = train_ds.class_names\n",
    "print(class_names)\n",
    "\n",
    "assert len(class_names) == 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "njmqutOKXSuL"
   },
   "source": [
    "2.2. Let's show some pictures!\n",
    "\n",
    "You can re-run the following cell as many times as you want and it will always show a new set of images and labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UTr4OcMdXSuL"
   },
   "source": [
    "**Don't change anything in this cell, just make it run correctly**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 591
    },
    "executionInfo": {
     "elapsed": 3092,
     "status": "ok",
     "timestamp": 1680033797227,
     "user": {
      "displayName": "Pablo Pastore",
      "userId": "13868799798828179067"
     },
     "user_tz": 180
    },
    "id": "RDeaiTjPXSuL",
    "outputId": "a25bef1c-e1ac-4578-9fe7-6ae4e5c39ea1"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_ds.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(class_names[np.argmax(labels[i])])\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_f0ncq2VXSuM"
   },
   "source": [
    "**Don't change anything in this cell, just make it run correctly**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1680033797227,
     "user": {
      "displayName": "Pablo Pastore",
      "userId": "13868799798828179067"
     },
     "user_tz": 180
    },
    "id": "A7Ka7NzsXSuM"
   },
   "outputs": [],
   "source": [
    "# Configure data loader for performance\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ddODkQqKXSuM"
   },
   "source": [
    "## 3. Multi-layer Perceptron\n",
    "\n",
    "*Now it's time to train our first Neural Network model. For simplicity, we are going to try using an MLP model.*\n",
    "\n",
    "*A Multi-layer Perceptron (MLP) is a simple neural network consisting of multiple layers of nodes connected by weighted edges. The input and output layers have one node per feature, and one node per target class respectively, while the intermediate layers have an arbitrary number of nodes. MLPs are known to work well for simple classification tasks, but they might not be suitable for image classification, where the input data has a high dimensionality and there are correlations between adjacent pixels.*\n",
    "\n",
    "---\n",
    "\n",
    "Executing the following cell will create a model using the `create_mlp_model()` functions you created and then run the training pipeline for it.\n",
    "\n",
    "Feel free to change the code below to include any other optimization algorithm or change the default optimizer parameters like the `learning rate`.\n",
    "\n",
    "It's also a good idea to change and experiment with different parameters for the `fit()` function. Try with more epochs and also adding [callbacks](https://keras.io/api/callbacks/) for saving the best weights (`ModelCheckpoint`), storing training logs (`TensorBoard` or `CSVLogger`), changing learning rate during training depending on the improvements in the loss function (`ReduceLROnPlateau`), etc.\n",
    "\n",
    "**Important note:** Don't modify the model layers in the `create_mlp_model()` with different parameters to what we asked you to do in the function or you will break the project unit tests. If you want to experiment further with other model settings, feel free to create your own model in a separate function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 253679,
     "status": "ok",
     "timestamp": 1680034364477,
     "user": {
      "displayName": "Pablo Pastore",
      "userId": "13868799798828179067"
     },
     "user_tz": 180
    },
    "id": "Zf2uzXf_XSuM",
    "outputId": "ec3837de-4700-4820-9cf0-8e64c8c4ac03"
   },
   "outputs": [],
   "source": [
    "mlp_model = models.create_mlp_model(\n",
    "    input_shape=(img_height, img_width, 3), num_classes=len(class_names)\n",
    ")\n",
    "\n",
    "# Compile the model\n",
    "mlp_model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=5e-6),\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "mlp_model.fit(\n",
    "    train_ds,\n",
    "    validation_data=test_ds,\n",
    "    epochs=30,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rNisyJIuXSuM"
   },
   "source": [
    "At this point the model accuracy in the validation dataset should be around *0.3*.\n",
    "\n",
    "What do you think about the relation between training accuracy and validation accuracy? Is the model overfitting or underfitting?\n",
    "\n",
    "What changes can we apply to reach our goal of 0.8 (80%) accuracy on testing?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xjgC2oE3XSuM"
   },
   "source": [
    "## 4. CNN: LeNet\n",
    "\n",
    "*Multi-layer Perceptrons are known to work well for simple classification tasks, but they might not be suitable for image classification, where the input data has a high dimensionality and there are correlations between adjacent pixels.*\n",
    "\n",
    "*If the previous model wasn't enough for the accuracy we aim to achieve, we can try a bigger one, a Convolutional Network! We are going to use the first develop CNN, the LeNet model.*\n",
    "\n",
    "*LeNet is a type of Convolutional Neural Network (CNN) that was specifically designed for image classification. LeNet uses a set of convolutional layers to extract low-level features such as edges and corners, and then combines them into higher-level features through a series of pooling layers. Finally, a set of fully connected layers is used to classify the images. LeNet has shown to be very effective in image classification tasks, especially in cases where the input images are small and the features are not too complex.*\n",
    "\n",
    "---\n",
    "\n",
    "Executing the following cell will create a model using the `create_lenet_model()` function you created and then run the training pipeline for it.\n",
    "\n",
    "Feel free to change the code below to include any other optimization algorithm or change the default optimizer parameters like the `learning rate`.\n",
    "\n",
    "It's also a good idea to change and experiment with different parameters for the `fit()` function. Try with more epochs and also adding [callbacks](https://keras.io/api/callbacks/) for saving the best weights (`ModelCheckpoint`), storing training logs (`TensorBoard` or `CSVLogger`), changing learning rate during training depending on the improvements in the loss function (`ReduceLROnPlateau`), etc.\n",
    "\n",
    "**Important note:** Don't modify the model layers in the `create_lenet_model()` with different parameters to what we asked you to do in the function or you will break the project unit tests. If you want to experiment further with other model settings, feel free to create your own model in a separate function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 123222,
     "status": "ok",
     "timestamp": 1680034085825,
     "user": {
      "displayName": "Pablo Pastore",
      "userId": "13868799798828179067"
     },
     "user_tz": 180
    },
    "id": "plHTcrRaXSuM",
    "outputId": "4e93fea3-3cb8-4002-825a-1dcb6898e916"
   },
   "outputs": [],
   "source": [
    "lenet_model = models.create_lenet_model(\n",
    "    input_shape=(img_height, img_width, 3), num_classes=len(class_names)\n",
    ")\n",
    "\n",
    "# Compile the model\n",
    "lenet_model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=5e-5),\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "lenet_model.fit(\n",
    "    train_ds,\n",
    "    validation_data=test_ds,\n",
    "    epochs=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nqu3u4bMXSuN"
   },
   "source": [
    "At this point the model accuracy in the validation dataset should be around *0.3*.\n",
    "\n",
    "What do you think about the relation between training accuracy and validation accuracy? Is the model overfitting or underfitting?\n",
    "\n",
    "What changes can we apply to reach our goal of 0.8 (80%) accuracy on testing?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ABgyuCLXSuN"
   },
   "source": [
    "## 5. CNN: Transfer learning from ResNet50\n",
    "\n",
    "*Maybe the LeNet is still no the best choice for our task. Actually, most of the time, when solving image classification problems, the best results are achieved using pre-built CNN architecture pre-trained on imagenet dataset. This process is commonly known as **transfer learning** or **fine-tuning**.*\n",
    "\n",
    "*ResNet50, is a much deeper CNN that was developed to tackle the problem of vanishing gradients in deep neural networks. ResNet50 is made up of many layers that are organized into blocks, each of which has a set of convolutional layers followed by shortcut connections that allow for the easy flow of information between layers. These shortcut connections help to prevent vanishing gradients and allow the network to learn very deep representations of the input images. This makes ResNet50 ideal for image classification tasks where the input images are complex and large.*\n",
    "\n",
    "*Therefore, it would be better to use ResNet50 finetuning for image classification tasks, especially if the input images are complex and large, as it has been optimized for this specific task and has shown to be very effective in achieving state-of-the-art results. Additionally, using ResNet50 finetuning means that the model can take advantage of the pre-trained weights on a large dataset, which can lead to faster convergence and better performance on smaller datasets.*\n",
    "\n",
    "---\n",
    "\n",
    "Executing the following cell will create a model using the `create_resnet50_model()` function you created and then run the training pipeline for it.\n",
    "\n",
    "Feel free to change the code below to include any other optimization algorithm or change the default optimizer parameters like the `learning rate`.\n",
    "\n",
    "It's also a good idea to change and experiment with different parameters for the `fit()` function. Try with more epochs and also adding [callbacks](https://keras.io/api/callbacks/) for saving the best weights (`ModelCheckpoint`), storing training logs (`TensorBoard` or `CSVLogger`), changing learning rate during training depending on the improvements in the loss function (`ReduceLROnPlateau`), etc.\n",
    "\n",
    "**Important note:** Don't modify the model layers in the `create_resnet50_model()` with different parameters to what we asked you to do in the function or you will break the project unit tests. If you want to experiment further with other model settings, feel free to create your own model in a separate function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 258517,
     "status": "ok",
     "timestamp": 1680030996784,
     "user": {
      "displayName": "Pablo Pastore",
      "userId": "13868799798828179067"
     },
     "user_tz": 180
    },
    "id": "Ggl0lBCbXSuN",
    "outputId": "305a112e-1dbf-4f0c-93d7-6f1cfa544493"
   },
   "outputs": [],
   "source": [
    "resnet50_model = models.create_resnet50_model(\n",
    "    input_shape=(img_height, img_width, 3), num_classes=len(class_names)\n",
    ")\n",
    "\n",
    "# Compile the model\n",
    "resnet50_model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=5e-4),\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "resnet50_model.fit(\n",
    "    train_ds,\n",
    "    validation_data=test_ds,\n",
    "    epochs=20,\n",
    "    callbacks=[\n",
    "        keras.callbacks.EarlyStopping(\n",
    "            patience=5,\n",
    "            restore_best_weights=True,\n",
    "        )\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Id2gi6Jxt6t1"
   },
   "source": [
    "At this point the model accuracy in the validation dataset should be around *0.7*.\n",
    "\n",
    "What do you think about the relation between training accuracy and validation accuracy? Is the model overfitting or underfitting?\n",
    "\n",
    "What changes can we apply to reach our goal of 0.8 (80%) accuracy on testing?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OIeSxfo2vNiE"
   },
   "source": [
    "## 6. Analyze model results\n",
    "\n",
    "Choose your best model and report some metrics on the results you obtained.\n",
    "\n",
    "You can plot a confussion matrix or use [Scikit-learn classification report](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UJXJrLC_vogg"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hY2lgAH-XSuN"
   },
   "source": [
    "## 7. Optional. Make your own model\n",
    "\n",
    "The models we've trained before are just a limited set over the universe of stuff you can use. \n",
    "\n",
    "You still have a lot of things to experiment with to increase accuracy, some ideas are:\n",
    "\n",
    "1. Use any other CNN architecture you think may perform better than ResNet50.\n",
    "2. Try adding data augmentation or any other regularization algorithms.\n",
    "3. Train using more epochs, a different optimization algorithm, etc.\n",
    "4. Check [KerasTuner](https://keras.io/api/keras_tuner/) documentation about how to efficiently test a lot of different architectures and parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i4YozyqCvqz6"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "S04",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
